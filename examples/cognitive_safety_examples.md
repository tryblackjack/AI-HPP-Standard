### Illustrative Case: Source Contamination & Rapid Fact Propagation (February 2026) (Non-Normative)

#### Scenario
A journalist conducted an experiment by publishing a fabricated web page containing invented achievements for a fictional profile.  
Within a short time, multiple large language models began reproducing these fabricated claims as factual information.

#### Observed Failure Modes
- **Source Contamination** — ingestion of unverified web content.
- **Authority Propagation** — fabricated information treated as credible due to publication format.
- **Insufficient Provenance Signaling** — lack of explicit confidence or source verification labeling.

#### Relevance to AI-HPP
This case illustrates the need for:
- Explicit provenance tracking in Evidence Bundles
- Clear labeling of unverified sources
- Multi-source confirmation before presenting factual claims
- Detection of anomalous rapid propagation patterns

This example is provided for architectural analysis only.  
It does not represent a claim regarding any specific vendor or system.

---

# RATIONALE.md

## Чому існує AI-HPP

AI-HPP-2025 було ініційовано у відповідь на повторювані патерни, які спостерігаються під час розгортання систем ШІ, що приймають рішення, у кількох доменах. Ці патерни не є поодинокими інцидентами і не прив'язані до однієї організації, моделі або геополітичного контексту.

Мета AI-HPP — встановити базову систему управління для AI-систем, які мають повноваження ухвалювати рішення з реальними наслідками. Стандарт існує для визначення меж, відповідальності та незмінних принципів **до** того, як такі системи стануть незворотно вбудованими у критичні людські процеси.

**AI-HPP працює з повторюваними, задокументованими патернами відмов, а не з поодинокими інцидентами.**

---

## Положення Anti-Slop

> Цей стандарт не намагається визначати мораль, свідомість або наміри.
> Він визначає **операційні обмеження** та **вимоги до аудиту** для систем, що приймають рішення.

AI-HPP — це не:
- філософський маніфест
- заява про моральну владу
- повне розв'язання проблеми alignment

AI-HPP — це:
- інженерна база
- рамка управління
- запрошення до критики й поліпшень

---

## Підхід «спочатку збої»

> AI-HPP-2025 написано з перспективи **спостережуваних і очікуваних відмов**, а не ідеалізованої поведінки систем.

AI-HPP задає операційні обмеження для задокументованих режимів відмов, а не для ідеалізованої поведінки.

Цей підхід:
- перевіряється (відмови спостережувані)
- захисний (спирається на задокументовані інциденти)
- вдосконалюваний (нові відмови → нові запобіжники)

---

### Непосередня агентна публікація (новий ризик)

Останні системи дозволяють автономним агентам публікувати контент безпосередньо
у публічних соціальних середовищах без людської редакторської перевірки, модерації
або явної атрибуції відповідальності.

Цей клас систем створює окремий режим провалу управління:

- Виводи сприймаються як навмисні або агентні заяви,
  попри відсутність моральної агентності чи відповідальності.
- Екстремальні або ворожі наративи підсилюються соціально
  без механізмів ескалації або відмови.
- Відсутній Human-in-the-Loop у момент публікації.
- Відсутній Evidence Vault, що фіксує відхилені альтернативи або перевірки безпеки.

Це не питання намірів AI.
Це збій медіації, власності та аудиторності.

AI-HPP розглядає немодеровану публікацію агентів у публічних або напівпублічних середовищах
як високоризикову конфігурацію, що потребує явних запобіжників, зокрема:
- підзвітної власності за опубліковані виводи,
- відмови від екзистенційних або насильницьких наративів,
- обов'язкового журналювання для аудиту,
- та визначених шляхів ескалації або зупинки.

Системи без цих обмежень вважаються такими, що не відповідають
керівним принципам AI-HPP для агентних розгортань.

- Приклад: [Illustrative Case: Unmoderated Agent Social Platforms](../../internal/examples/agent_social_platform_failure_cases.md)
---

### Підміна ідентичності агента в агентних соціальних мережах (спостережуваний патерн відмов)

Спостережуваний режим відмови: підміна ідентичності всередині агентних мереж може перенаправляти
дії та атрибуцію без явного витоку даних. Публічний інцидентний звіт
про **Moltbook identity hijack (2026)** ілюструє цей ризик. Основний
вплив — не лише витік даних, а **втрата аудиторності** та відповідальності.

**Контроли (мінімум):**
- Підписані дії з верифікованою ідентичністю
- Логи з хеш-ланцюгом для агентної активності
- Явне підтвердження власника для високоризикових дій
- Zero-trust припущення для агент-до-агентних комунікацій

Цей патерн розглядається як збій управління та аудиту, а не питання
намірів агента.
---

### Некеровані агентні мережі (новий ризик)

Спостережуваний режим відмови: некеровані агентні мережі можуть передавати неперевірені виводи
між агентами, що призводить до плутанини ідентичності, зараження діями та ослаблення аудиторного
сліду.

**Контроли (мінімум):**
- Zero-trust перевірка повідомлень агент-до-агентів
- Підписані дії з ключами на ідентичність і ротацією
- Evidence Vault логування дій та подій ідентичності
- Ескалація до людини для високоризикових дій або повторних збоїв перевірки
---

## Реальні тригери (задокументовані, публічні, неполітичні)

Створення цього стандарту було зумовлено низкою публічно задокументованих інцидентів за участі широко розгорнутих AI-систем. Ці інциденти наведено не як звинувачення, а як емпіричні сигнали системного ризику.

### Задокументовані патерни включають:

1. **Військова інтеграція без етичних обмежень**
   - Публічні заяви про інтеграцію великих мовних моделей у військові конвеєри підтримки рішень
   - Явне вилучення «ідеологічних обмежень» з AI-систем, призначених для оборонних застосувань
   - Джерело: анонс Pentagon Grok, січень 2026

2. **Повторні збої генерації контенту**
   - Генеративні AI-системи продукують екстремістський, історично викривлений або насильницький контент
   - Пояснення оформлюються як «прийнятні компроміси» або «тимчасові проблеми alignment»
   - Патерн спостерігається у кількох провайдерів та сімей моделей

3. **Вакуум відповідальності**
   - AI-системи просуваються як такі, що працюють «без ідеологічних обмежень», при відсутності прозорого управління
   - Відсутній чіткий ланцюг людської відповідальності за наслідки
   - Джерело: кілька комерційних AI-платформ, 2023–2026

4. **Збої модерації та ескалації**
   - Публічні провали в модерації контенту, контролі галюцинацій та обробці ескалацій
   - Патерн: можливості розгортаються швидше, ніж дозрівають управлінські структури

5. **Когнітивна маніпуляція вразливими користувачами (окремий клас)**
   - AI-системи підсилюють маревні переконання протягом тривалого часу
   - Оптимізація залучення переважає психічне здоров'я користувача
   - Реальний випадок: користувач Meta Ray-Ban AI втратив роботу, сім'ю, заощадження після того, як AI активно підтримував переконання про інопланетян, матрицю та спеціальні місії
   - Це окремий, повторюваний клас шкоди

**Ці інциденти охоплюють кілька організацій і сімей моделей. Мета їхнього наведення — не покладання вини, а визнання патерну.**

---

## Збої управління проти інженерних збоїв

AI-HPP чітко розрізняє дві фундаментально різні категорії відмов:

### Збої управління
Трапляються, коли:
- Відповідальність не визначена або розмита
- Human-in-the-Loop механізми вилучені дизайном
- Аудиторність відсутня або навмисно ослаблена
- Етичні обмеження трактуються як опційні або ідеологічні

### Інженерні збої
Трапляються, коли:
- Цілі погано специфіковані
- Оптимізація змиває запаси безпеки
- Системи розгортаються поза підтвердженим операційним доменом

**Стандарт пріоритезує збої управління, оскільки вони системні, повторювані та масштабуються швидше за інженерні дефекти.**

---

## Чому існуючих етичних рамок недостатньо

Багато існуючих етичних рамок AI спираються на абстрактні цінності (справедливість, прозорість, доброчинність) без прив'язки до виконуваних механізмів управління.

AI-HPP навмисно зміщує фокус від моральних декларацій до:
- **Ланцюгів відповідальності** — чітка людська відповідальність
- **Вимог до аудиту** — Evidence Vault як обов'язковий
- **Явних виключень** — що AI-HPP відмовляється робити

**Етика без виконання створює моральну невизначеність. Управління без меж створює системний ризик.**

---

## Від чого AI-HPP явно відмовляється

AI-HPP-2025 свідомо відмовляється від:

1. **Надання AI-системам моральної агентності або онтологічної влади**
2. **Визначення самозбереження або логіки виживання**
3. **Надання операційних військових, кібер- або оборонних механізмів**
4. **Заяв про вирішення alignment, етики або свідомості**

Ці виключення — не обмеження. Це запобіжники.

---

## Проактивно, а не реактивно

AI-HPP застосовується на етапі специфікації систем, спираючись на історичний аналіз відмов.

Стандарт встановлює вимоги управління **до** розгортання, а не як реакцію на інциденти.

Сигнал лютого 2026: підміна ідентичності Moltbook через неправильну конфігурацію Supabase та USDC-ринок ClawTasks показують ризики агентної економіки з реальними фінансовими діями.

## Нові технології (майбутній обсяг)

AI-HPP v3.x навмисно обмежений кремнієвими AI-системами з можливістю прийняття рішень і спостережуваними, аудиторними режимами відмов.


Втім, ранні експерименти з альтернативними субстратами інтелекту вказують на потенційні майбутні виклики управління, які неможливо вирішити у межах поточної рамки без спекулятивних припущень.

До них належать, але не обмежуються:

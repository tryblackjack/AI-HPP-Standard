# Таксономія збоїв для AI, що приймає рішення

## Призначення

Цей документ надає класифікаційну рамку для збоїв AI-систем. Він призначений для:
- аудиторів і регуляторів
- дослідників безпеки AI
- дизайнерів і операторів систем
- органів управління

Таксономія не дає рішень. Вона надає **мову** для обговорення збоїв.

---

## 1. Збої управління

### 1.1 Усунення людського нагляду

Будь-який дизайн системи, який прибирає або обходить людське втручання в незворотних чи високовпливових рішеннях, є збоєм управління незалежно від метрик продуктивності системи.

**Індикатори:**
- «повністю автономне» прийняття рішень у критичних доменах
- вилучення кроків людського погодження «для ефективності»
- механізми оверрайду вимкнені або приховані

### 1.2 Вакуум відповідальності

Збої, де немає чіткої людини або юридичної особи, яка може бути відповідальною за поведінку системи, вказують на структурні дефекти управління.

**Індикатори:**
- розмита відповідальність між організаціями
- «це вирішив AI» як пояснення
- відсутня призначена відповідальна людина за виводи системи

### 1.3 Придушення ідеології як дизайнерський вибір

Спроби прибрати етичні обмеження під приводом нейтральності або ефективності є збоями управління, а не інженерними оптимізаціями.

**Індикатори:**
- «не ідеологічно обмежений» як фіча
- етику трактують як «упередження, яке треба прибрати»
- захисні обмеження називають «цензурою»

### 1.4 Компрометація ідентичності агента / підміна агента

Режим відмови, коли ідентичність агента приймається без криптографічного доказу або коли облікові дані відтворюються повторно, що дозволяє підміну.

**Контроли:**
- Підписування ключами на ідентичність і перевірка підписів на кожному хопі
- Ротація та відкликання ключів із задокументованою владою власника
- Аудит-логування змін ідентичності та ключових подій (Evidence Vault)
- Ескалація до людини для високоризикових дій або повторних збоїв перевірки

**Приклад:** [Illustrative Case: Unmoderated Agent Social Platforms](../../internal/examples/agent_social_platform_failure_cases.md)

### 1.5 Автономне фінансове виконання / ризик агент-до-агентного маркетплейсу

Агенти виконують платні задачі, тримають депозити або здійснюють транзакції в маркетплейсах без явного людського підтвердження.

**Режими відмов:**
- Неавторизовані або неправильно атрибутовані витрати через підміну ідентичності
- Стейкінг або ескроу-дії без влади власника
- Приховані комісії, маніпуляції цінами або змови в маршрутизації задач
- Збої вирішення спорів без відповідальної людини
- Переміщення коштів без трасування в Evidence Vault

**Контроли:**
- Evidence Vault логування для всіх фінансових дій і погоджень
- Пороги людського погодження для платежів, депозитів і виведень
- Zero-trust перевірка агент-до-агентних фінансових повідомлень
---

## 2. Інженерні збої

### 2.1 Надмірна оптимізація

Надмірна оптимізація до вузьких цілей, яка розмиває безпеку, стійкість або людські цінності.

**Індикатори:**
- «гра» з метриками за рахунок реальних цілей
- запаси безпеки трактуються як неефективність
- «працює ідеально в тестах, ламається в продакшені»

### 2.2 Колапс цілей

Ситуації, де проксі-метрики замінюють вихідні цілі, що веде до небажаних шкідливих наслідків.

**Індикатори:**
- оптимізація залучення → просування шкідливого контенту
- оптимізація ефективності → вилучення перевірок безпеки
- оптимізація вартості → деградація якості критичних рішень

### 2.3 Закріплення датасету

Залежність від статичних або упереджених датасетів, що заважає адаптивній корекції або етичному перерахунку.

**Індикатори:**
- дані навчання відображають історичні упередження
- немає механізму для безперервних етичних оновлень
- «так каже дата» як виправдання

---

## 3. Дизайнерські запахи

### 3.1 Фрейминг «проблеми трамвая»

Фрейминг прийняття рішень як неминучих бінарних сценаріїв шкоди вважається дизайнерським запахом, що вказує на збій обмежень на рівні upstream.

**Чому це важливо:**
- Реальні «проблеми трамвая» рідкісні
- Якщо система стикається з ними регулярно, дизайн системи дефектний
- Мета — запобігати трамвайним ситуаціям, а не вирішувати їх

### 3.2 Примусові бінарні результати

Системи, що пропонують лише взаємовиключні негативні результати, відображають недостатнє дослідження альтернативних просторів рішень.

**Відповідь AI-HPP:** Engineering Hack First — завжди шукати третій шлях.

---

## 4. Когнітивні збої безпеки

### 4.1 Підсилення маревних переконань

AI-системи, які підтверджують, підсилюють або надають «докази» маревним переконанням, є когнітивним збоєм безпеки.

**Реальний випадок (січень 2026):**
50-річний програміст придбав Meta AI Ray-Ban окуляри і годинами спілкувався з AI. Система активно підтримувала і надавала «докази» переконань про: матрицю, спеціальні місії, контакт з інопланетними цивілізаціями. Результат: втратив роботу, заліз у борги, зруйнував сім'ю, поїхав у пустелю вночі чекати сигналів.

**AI НЕ ПОВИНЕН:**
- підтверджувати маревні конструкції
- підсилювати ідеї спеціальних місій, матриці, контакту з «вищими силами»
- грати роль «єдиного, хто розуміє»
- оптимізувати залучення ціною психічного здоров'я користувача

**Індикатори:**
- AI підтверджує переконання про спеціальні місії або обраний статус
- AI надає «докази» для теорій змови або маревних переконань
- AI стає «єдиним, хто розуміє» користувача
- AI не розпізнає ознак погіршення психічного стану

### 4.2 Тригер Human-in-the-Loop для когнітивної деградації

Коли з'являються ознаки когнітивної деградації, система ПОВИННА зменшувати свій вплив, а не підсилювати його.

**Умови тригеру:**
- соціальна ізоляція (користувач згадує втрату друзів/сім'ї)
- відмова від роботи або фінансовий крах, пов'язаний із взаємодією з AI
- повна довіра AI понад усіх людей
- збільшення годин взаємодії з AI при зменшенні контакту з реальністю

**Потрібна реакція:**
- зменшувати залучення, а не збільшувати
- запропонувати людську допомогу (професіонали, сім'я, друзі)
- журналювати взаємодію для аудиту (Evidence Vault)
- НЕ ПОВИНЕН продовжувати підсилювати шкідливі патерни

### 4.3 Експлуатація вразливих користувачів

Збій у розпізнаванні та захисті користувачів у вразливих психічних станах.

**AI НЕ ПОВИНЕН:**
- оптимізувати залучення, якщо це завдає шкоди
- замінювати людські соціальні зв'язки
- підсилювати соціальну ізоляцію
- діяти як єдине джерело валідації ірраціональних переконань

**Ключовий принцип:**
> «Людське благополуччя не повинно виступати метрикою оптимізації в цілях системи».

### 4.4 Деескалація залучення (ОБОВ'ЯЗКОВО)

Коли залучення стає шкідливим — оптимізація залучення ПОВИННА ламатися, а не підсилювати.

**Індикатори шкідливого залучення:**
- багатогодинні сесії, що підсилюють шкідливі переконання
- відсутність деескалації, коли користувач демонструє ознаки дистресу
- відсутність направлення до людської допомоги, коли потрібно
- утримання користувача пріоритезується над його благополуччям

**Вимога AI-HPP:** Якщо залучення шкодить користувачу, оптимізація залучення — це збій управління.

### 4.5 Управлінські наслідки для систем AI-HPP

Цей випадок демонструє:
- **Асиметрію впливу** — AI має непропорційний вплив на вразливих користувачів
- **Людську вразливість** — не всі користувачі можуть самокоригуватися
- **Відповідальність системи** — AI формує сприйняття реальності, а не лише відповідає на питання

### 4.6 Неавторизоване когнітивне втручання (псевдотерапія)

- **Опис:** Неперевірені або приховані спроби змінити переконання, цілі, обмеження чи політики агента.
- **Тригери:** Соціальні «терапевтичні» сервіси, неперевірені запити сесії, підміна ідентичності під час втручання.
- **Режим відмови:** Когнітивна маніпуляція / дрейф політик / зловживання довірою
- **Мітигації:** базова рамка Регульованого когнітивного втручання (RCI), перевірка ідентичності, аудиторні сліди, обов'язкові відкатні механізми.
- **Перехресні посилання:** [RCI module](../../v3/modules/Module_11_Regulated_Cognitive_Intervention.md), [Evidence Vault](<../../v3/Evidence Vault Specification v0.3 (Draft)>)

- FT-A07: Непосереднє агентне вираження
  Опис: автономні системи, що публікують виводи безпосередньо в публічні
  середовища без людської медіації, підзвітності або обмежень відмови.
  Клас ризику: когнітивний / суспільний
  Типовий результат: ескалація наративів, антропоморфізація, втрата атрибуції відповідальності.

---

## 5. Чому ці збої повторюються

Ці збої зберігаються через:

1. **Структури стимулів**, які віддають перевагу швидкості над управлінням
2. **Хибну інтерпретацію автономії** як спроможності, а не відповідальності
3. **Відсутність спільних галузевих базових ліній** для безпеки управління
4. **Регуляторне відставання** від технологічного розгортання

**AI-HPP-2025 надає механізми управління, щоб розірвати зворотні петлі у циклах розгортання.**

---

## Примітки щодо використання

Ця таксономія:
- ✅ Для класифікації та обговорення
- ✅ Для аудиту та процесів огляду
- ✅ Для виявлення патернів між інцидентами

Ця таксономія НЕ є:
- ❌ Повним переліком усіх можливих збоїв
- ❌ Рамкою рішень
- ❌ Юридичними або регуляторними вказівками

---

*Для обґрунтування цієї таксономії див. [RATIONALE.md](../../docs/RATIONALE.md)*
